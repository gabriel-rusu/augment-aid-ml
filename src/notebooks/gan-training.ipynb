{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Training a GAN on Fashion MNIST"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80999af1f3927b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting for hot reloading of modules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad239bc6ba06a086"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1d7ea5433e412cb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importing modules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621eee24479ed310"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.discriminator import Discriminator\n",
    "from src.models.generator import Generator\n",
    "from src.train.wrapper.gan_wrapper import GANWrapper\n",
    "from src.utils.constants import Paths\n",
    "from src.utils.helpers import detect_device, matplotlib_imshow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3621dbfcf153ae08",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting up the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d704c6751baf3016"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75f30dcd584de702",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Downloading and preparing the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d913439efd7c9d82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST(Paths.DATA_DIR, train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST(Paths.DATA_DIR, train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining the model hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2b05aff5ce4feea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "z_dim = 128\n",
    "num_classes = len(classes)\n",
    "generator_input_dim = z_dim + num_classes\n",
    "input_channels = 1\n",
    "discriminator_input_dim = input_channels + num_classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2e13a2b5caf12a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualizing the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5179e4081d0a348e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45d1fab42597efdf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfb43e7e68aa763f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generator = Generator(generator_input_dim, input_channels)\n",
    "discriminator = Discriminator(discriminator_input_dim)\n",
    "\n",
    "gan_wrapper = GANWrapper(generator, discriminator, z_dim, num_classes, display_every_n_steps=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bac1432d1b4faf2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining the training parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46c77ad02dc17f60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(Paths.LOGS_DIR, name='gan_training.logs')\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=Paths.MODEL_CHECKPOINT_DIR,\n",
    "                                      filename='gan-{epoch:02d}-{val_generator_loss:.2f}', save_top_k=3,\n",
    "                                      monitor='val_generator_loss')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc7df325129658fd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3234c495db9fb452"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /logs/gan_training.logs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72138ce2331bf642",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e216b4222ad4fa57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer = L.Trainer(default_root_dir=Paths.MODEL_CHECKPOINT_DIR, max_epochs=10000, callbacks=[checkpoint_callback],\n",
    "                    logger=logger, accelerator=detect_device(), enable_checkpointing=True, log_every_n_steps=100)\n",
    "\n",
    "trainer.fit(gan_wrapper, train_dataloaders=training_loader, val_dataloaders=validation_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bdb44c91592cbcf",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
